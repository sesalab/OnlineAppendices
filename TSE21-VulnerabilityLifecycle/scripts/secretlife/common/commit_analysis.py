import datetime as dt
import re
from collections import Counter

from tqdm import tqdm

from utils import adjust_message, rescale_value

newfeature_keywords = {'new', 'feature', 'add', 'creat', 'introduc', 'implement'}
bugfixing_keywords = {'fix', 'repair', 'error', 'bug', 'issue', 'exception'}
enhancement_keywords = {'updat', 'modif', 'upgrad', 'export', 'remov', 'integrat', 'support', 'enhancement', 'replac', 'includ', 'expos', 'generat', 'migrat'}
refactoring_keywords = {'renam', 'reorganiz', 'refactor', 'clean', 'polish', 'mov', 'extract', 'reorder', 're-order', 'merg'}


def get_commit_goals(commit_message):
    msg = commit_message.lower()
    goals = {
        "new_feature": int(any(k in msg for k in newfeature_keywords)),
        "bug_fixing": int(any(k in msg for k in bugfixing_keywords)),
        "enhancement": int(any(k in msg for k in enhancement_keywords)),
        "refactoring": int(any(k in msg for k in refactoring_keywords))
    }
    return goals


def get_number_goals(commits):
    counter = Counter()
    for c in commits:
        counter.update(get_commit_goals(adjust_message(c.msg)))
    return counter


def get_num_authors(commits, upper_date):
    return len({c.author.email for c in commits if c.author_date <= upper_date})


def get_authors_first_authored_date(commits):
    authors_first_date = {}
    for commit in commits:
        author = commit.author.email
        if author not in authors_first_date.keys():
            authors_first_date[author] = commit.author_date
    return authors_first_date


def get_commits_workloads(commits, upper_date):
    lower_date = upper_date - dt.timedelta(days=29)
    authors = [c.author.email for c in commits if lower_date <= c.author_date and c.author_date <= upper_date]
    counter = Counter(authors)
    return counter


def get_churn_workloads(commits, upper_date):
    lower_date = upper_date - dt.timedelta(days=29)
    valid_commits = [c for c in commits if lower_date <= c.author_date and c.author_date <= upper_date]
    authors = {}
    for a in tqdm({c.author.email for c in valid_commits}):
        authors[a] = sum(map(lambda c: c.lines, filter(lambda c: c.author.email == a, valid_commits)))
    return authors


def get_tenures(commits, reference_date):
    authors_first_date = get_authors_first_authored_date(commits)
    tenures = {}
    for author in authors_first_date.keys():
        first_date = authors_first_date[author]
        elapsed_months = (reference_date.year - first_date.year) * 12 + reference_date.month - first_date.month
        if elapsed_months >= 0:
            tenures[author] = elapsed_months
    return tenures


def get_commit_info(git_repo, commit_hash, commits):
    commit = git_repo.get_commit(commit_hash)
    message = adjust_message(commit.msg)
    date = commit.author_date

    author = commit.author.email
    commits_workloads = get_commits_workloads(commits, date)
    churn_workloads = get_churn_workloads(commits, date)
    tenures = get_tenures(commits, date)
    
    author_commits_workload = rescale_value(commits_workloads, author)
    author_churn_workload = rescale_value(churn_workloads, author)
    author_tenure = rescale_value(tenures, author)

    releases_with_commit = git_repo.repo.git.tag("--contains", commit_hash, "--sort=creatordate", "--format=%(refname:strip=2);%(creatordate:iso)").splitlines()
    if len(releases_with_commit) > 0:
        nearest_release = next(r for r in releases_with_commit if r.split(";")[1] != "")
        nearest_release_name = nearest_release.split(";")[0]
        nearest_release_date = dt.datetime.strptime(nearest_release.split(";")[1], "%Y-%m-%d %H:%M:%S %z")
    else:
        nearest_release_name = ""
        nearest_release_date = ""

    added_lines = 0
    removed_lines = 0
    for mod in commit.modified_files:
        added_lines += mod.added_lines
        removed_lines += mod.deleted_lines

    commit_info = {
        "hash": commit_hash,
        "message": message,
        "date": str(date),
        "author": author,
        "author_commits_workload": round(author_commits_workload, 3),
        "author_churn_workload": round(author_churn_workload, 3),
        "author_tenure": round(author_tenure, 3),
        "nearest_release_name": str(nearest_release_name),
        "nearest_release_date": str(nearest_release_date),
        "added_lines": added_lines,
        "removed_lines": removed_lines
    }
    return commit_info


def count_commits_between(git_repo, from_hash, to_hash, file=None):
    args = ["--count", "--no-merges", f"{from_hash}..{to_hash}"]
    if file:
        args.append("--")
        args.append(file)
    return int(git_repo.repo.git.rev_list(*args))


def count_previous_changes(git_repo, from_hash, to_hash, file=None):
    args = ["--no-merges", "--pretty=oneline", f"{to_hash}"]
    if file:
        args.append("--follow")
        args.append("--")
        args.append(file)
    from_creation_commits = git_repo.repo.git.log(*args).splitlines()[::-1]
    counter = 0
    for c in from_creation_commits:
        if from_hash in c:
            break
        counter += 1
    return counter


def get_number_commits_since_creation(git_repo, file, until_hash, starting_hash):
    # Follow all commits on the given file, counting renames too (default threshold at 50%). Possible duplicates are removed
    past_hashes = list(dict.fromkeys(git_repo.repo.git.log("--follow", "--author-date-order", "--pretty=format:%H", starting_hash, "--", file).splitlines()))[::-1]
    try:
        number_commits_since_creation = past_hashes.index(until_hash) + 1
    except ValueError:
        # If the until_commit is not found it could be a merge commit, we rerun the git log with -m option
        past_hashes_merges = list(dict.fromkeys(git_repo.repo.git.log("--follow", "-m", "--author-date-order", "--pretty=format:%H", starting_hash, "--", file).splitlines()))[::-1]
        try:
            number_commits_since_creation = past_hashes_merges.index(until_hash) + 1
        except ValueError:
            raise
    return number_commits_since_creation


"""
Returns True if the line is empty or starts with known comment lines
"""
def is_useless_line(line):
    return not line or \
            line.startswith("//") or \
            line.startswith("/*") or \
            line.startswith("*") or \
            line.startswith("#") or \
            line.startswith("'''") or \
            line.startswith('"""') or \
            line.startswith("=begin") or \
            line.startswith("<#") or \
            line.startswith("--") or \
            line.startswith("{-") or \
            line.startswith("--[[") or \
            line.startswith("<!--")


def parse_hunks(diff):
    hunk_headers_indexes = []
    diff_lines = diff.splitlines()
    for index, diff_line in enumerate(diff_lines):
        if diff_line.startswith("@@ -"):
            hunk_headers_indexes.append(index)
    
    hunks_text = []
    for index, hunk_line in enumerate(hunk_headers_indexes):
        if not index == len(hunk_headers_indexes) - 1:
            hunk_text = diff_lines[hunk_line:hunk_headers_indexes[index + 1]]
        else:
            hunk_text = diff_lines[hunk_line:]
        hunks_text.append(hunk_text)

    hunks = []
    for hunk_text in hunks_text:
        hunk = {}
        hunk["raw_text"] = diff

        hunk["header"] = hunk_text[0]
        old = re.search("@@ -(.*) \+", hunk["header"]).group(1).strip().split(",")
        # Ignore subprojects commit hunks, which are very rare
        if len(old) < 2:
            continue
        hunk["old_start_line"] = old[0]
        hunk["old_length"] = old[1]
        new = re.search(".*\+(.*) @@", hunk["header"]).group(1).strip().split(",")
        # Ignore very small hungs, which are very rare
        if len(new) < 2:
            continue
        hunk["new_start_line"] = new[0]
        hunk["new_length"] = new[1]
        code_context = hunk["header"][hunk["header"].rfind("@") + 2:].strip()
        hunk["code_context"] = code_context

        change_block = [(i,line) for i, line in enumerate(hunk_text) if line.startswith("+") or line.startswith("-")]
        start_index = change_block[0][0]
        end_index = change_block[-1][0]
        hunk["before_ctx"] = hunk_text[1:start_index]
        hunk["change_block"] = [el[1] for el in change_block]
        hunk["after_ctx"] = hunk_text[end_index + 1:]
        hunks.append(hunk)
    return hunks
