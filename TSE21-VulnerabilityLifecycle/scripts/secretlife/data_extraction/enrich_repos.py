import json
import os
import shutil
import sys

from pydriller import Git

from enrich_fixes import enrich_fixes

sys.path.insert(0, "../common")
from commit_analysis import (count_commits_since_creation, get_num_authors,
                             get_number_goals)
from utils import (call_api, export_update, get_full_project_name,
                   get_processed_cves, get_repos,
                   is_git_repo, str_to_datetime)


def clean_repo(git_repo, repo_path_tmp):
    git_repo.clear()
    del git_repo
    shutil.rmtree(repo_path_tmp)


tmp = "/tmp"
date_to_checkout = "2020-11-01 23:59:59+00:00"
in_filepath = "../../../data/cves.json"


if len(sys.argv) < 2:
    print("Need to specify a path containing the cloned repositories. Exiting.")
    sys.exit(1)
repos_dir = sys.argv[1] # ../../../data/repos/
# Ensure the supplied path is valid 
if not os.path.isdir(repos_dir):
    print("The specified path does not exist. Exiting.")
    sys.exit(1)
if len(sys.argv) < 3:
    print("Need to specify the output file containing the enriched repositories. Exiting.")
    sys.exit(1)
enriched_repos_out_filepath = sys.argv[2] # ../../../data/repos_enriched.json
if len(sys.argv) < 4:
    print("Need to specify the output file containing the discarded repositories. Exiting.")
    sys.exit(1)
discarded_repos_out_filepath = sys.argv[3] # ../../../data/repos_discarded.json
if len(sys.argv) < 5:
    print("The Username:Token was not specified. Will not fetch additional data.")
else:
    user_token = sys.argv[4] # username:token

# Import repository names from the input json
cves = []
with open(in_filepath, "r") as in_file:
    cves = json.load(in_file)
all_repos = get_repos(cves)

if not os.path.exists(enriched_repos_out_filepath):
    with open(enriched_repos_out_filepath, 'w'):
        pass
if not os.path.exists(discarded_repos_out_filepath):
    with open(discarded_repos_out_filepath, 'w'):
        pass

num_repos = len(all_repos)
print("Repositories to enrich: {}".format(num_repos))
current_repo = 0
for repo_url in all_repos:
    current_repo += 1
    print("\n({}/{}) Working on {}".format(current_repo, num_repos, repo_url))

    # Get the remaining CVEs (if any)
    all_cves = list(filter(lambda x: x["fixes"][0]["repo"] == repo_url, cves))
    enriched_cves = get_processed_cves(enriched_repos_out_filepath, repo_url)
    remaining_cves = [cve for cve in all_cves if cve["cve"] not in {ec["cve"] for ec in enriched_cves}]
    if len(remaining_cves) == 0:
        print(f"The repository has no remaining CVEs to analyze: Skipping")
        continue

    # Find the local repository in the specified directory
    full_project_name = get_full_project_name(repo_url)
    repo_path = os.path.join(repos_dir, full_project_name)
    if not os.path.exists(repo_path) or not is_git_repo(repo_path):
        print(f"There is no cloned repository from {repo_url}: Skipping for now")
        continue
    # After the cloned repository is found, move it into /tmp
    repo_path_tmp = os.path.join(tmp, full_project_name)

    if os.path.exists(repo_path_tmp):
        shutil.rmtree(repo_path_tmp)
    print("Copying into /tmp...")
    shutil.copytree(repo_path, repo_path_tmp, symlinks=True, ignore_dangling_symlinks=True)
    git_repo = Git(repo_path_tmp)
    # This is the way to get the default branch bypassing the detached HEAD issue with GitPython
    if len(git_repo.repo.heads) == 0:
        print(f"The repository {repo_url} is empty: Discarding")
        export_update({"repo": repo_url, "reason": "INVALID"}, discarded_repos_out_filepath)
        clean_repo(git_repo, repo_path_tmp)
        continue
    main_branch_name = git_repo.repo.heads[0]
    # Move to last commit before the date of the study
    commit_to_checkout = git_repo.repo.git.rev_list("-n", "1", "--first-parent", f'--until="{date_to_checkout}"', main_branch_name, "--")
    if not commit_to_checkout:
        print(f"The repository {repo_url} is empty: Discarding")
        export_update({"repo": repo_url, "reason": "INVALID"}, discarded_repos_out_filepath)
        clean_repo(git_repo, repo_path_tmp)
        continue
    git_repo.checkout(commit_to_checkout)

    # The subsequent analysis are robust to amendments if we ensure the sorting by the author_date
    commits = sorted(list(git_repo.get_list_commits()), key=lambda c: c.author_date)

    # Get repository general data
    enriched_repo = {
        "repo": repo_url,
        "creation_date": str(commits[0].author_date),
        "commits": count_commits_since_creation(git_repo, "HEAD"),
        "goals": get_number_goals(commits),
        "authors": get_num_authors(commits, str_to_datetime(date_to_checkout))
    }
    if user_token:
        org_name = repo_url.rsplit('/', 2)[1]
        project_name = repo_url.rsplit('/', 2)[2]
        repo_endpoint = f"https://{user_token}@api.github.com/repos/{org_name}/{project_name}"
        repo_response = call_api(repo_endpoint)
        enriched_repo["stars"] = repo_response["stargazers_count"]
        enriched_repo["forks"] = repo_response["forks_count"]
        if repo_response["language"]:
            enriched_repo["language"] = repo_response["language"]
        else:
            lang_endpoint = f"{repo_endpoint}/languages" 
            lang_response = call_api(lang_endpoint)
            if len(lang_response) == 0:
                enriched_repo["language"] = "N/A"
            else:
                enriched_repo["language"] = max(lang_response, key=lang_response.get)

    # Loop on CVEs
    num_all_cves = len(all_cves)
    num_remaining_cves = len(remaining_cves)
    print(f"Going to analyze {num_remaining_cves}/{num_all_cves} CVEs")
    current_repo_cve = 0
    for repo_cve in remaining_cves:
        current_repo_cve += 1
        print("\nProcessing {} ({}/{})".format(repo_cve["cve"], current_repo_cve, num_remaining_cves))
        enriched_fixes = enrich_fixes(git_repo, repo_cve["fixes"], commits)
        if len(enriched_fixes) == 0:
            print("Discarding {}: no viable fixing commits".format(repo_cve["cve"]))
        else:
            enriched_cves.append({
                "cve": repo_cve["cve"],
                "cwe": repo_cve["cwe"],
                "cvss": repo_cve["cvss"],
                "cvss-vector": repo_cve["cvss-vector"],
                "fixes": enriched_fixes
            })
            # Save the current progresses
            enriched_repo["cves"] = enriched_cves
            export_update(enriched_repo, enriched_repos_out_filepath)
    
    if len(enriched_cves) == 0:
        print(f"The repository {repo_url} has no valid CVEs: Discarding")
        export_update({"repo": repo_url, "reason": "INVALID"}, discarded_repos_out_filepath)
    del enriched_repo
    clean_repo(git_repo, repo_path_tmp)
