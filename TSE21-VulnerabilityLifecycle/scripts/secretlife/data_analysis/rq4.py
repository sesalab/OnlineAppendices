import os
import sys

import pandas as pd

if len(sys.argv) < 2:
    print("Need to specify the directory containing the input data. Exiting.")
    sys.exit(1)
input_dir = sys.argv[1] # e.g., ../../../data/
if len(sys.argv) < 3:
    print("Need to specify the directory containing the output data. Exiting.")
    sys.exit(1)
output_dir = sys.argv[2] # e.g., ../../../results/

input_filepath = os.path.join(input_dir, "rq4_input.csv")
top_25_filepath = os.path.join(input_dir, "top25cwe.csv")
output_filepath = os.path.join(output_dir, "rq4/output.txt")

overall_summary_filepath = os.path.join(output_dir, "rq4/overall_summary.csv")
category_summary_filepath = os.path.join(output_dir, "rq4/category_summary.csv")

df_fix_cves = pd.read_csv(input_filepath, delimiter=",")
categories_groups = df_fix_cves.groupby("fixCategory", sort=False)
languages_groups = df_fix_cves.groupby("language", sort=False)
top_25 = pd.read_csv(top_25_filepath)[["cwe", "position"]]
df_cves_top_25 = df_fix_cves[df_fix_cves["cwe"].isin(top_25["cwe"])] \
    .merge(top_25, how="left", on="cwe") \
    .sort_values("position", ignore_index=True) \
    .drop(columns=["position"])
df_cves_top_25_groups = df_cves_top_25.groupby("cwe", sort=False)

# General Profiling
num_pairs = len(df_fix_cves)
num_cves = df_fix_cves["cve"].nunique()
num_cwes = df_fix_cves["cwe"].nunique()
num_repos = len(df_fix_cves.groupby(["orgName", "projectName"]))
num_categories = len(categories_groups)

# (Overall) Summary + Summary Divided per Fix Category
df_fix_cves.describe().to_csv(overall_summary_filepath)
categories_groups.describe().to_csv(category_summary_filepath)

# (Overall) Frequency Distribution of Fix Categories
categories_occurances = pd.DataFrame(categories_groups.size().sort_values(ascending=False), columns=["count"])
categories_occurances["perc"] = categories_occurances["count"] / num_pairs * 100

# (Per CWEs) Frequency Distribution of Fix Categories 
categories_freq = df_cves_top_25_groups["fixCategory"].value_counts()
categories_total = df_cves_top_25_groups["fixCategory"].count()
categories_freq_total = pd.merge(categories_freq, categories_total, left_index=True, right_index=True)
categories_freq_total.rename({
    "fixCategory_x": "count",
    "fixCategory_y": "total"
}, axis=1, inplace=True)
categories_freq_total["perc"] = categories_freq_total["count"] / categories_freq_total["total"] * 100

# (Per Language) Frequency Distribution of Fix Categories
languages_freq = languages_groups["fixCategory"].value_counts()
languages_total = languages_groups["fixCategory"].count()
language_freq_total = pd.merge(languages_freq, languages_total, left_index=True, right_index=True)
language_freq_total.rename({
    "fixCategory_x": "count",
    "fixCategory_y": "total"
}, axis=1, inplace=True)
language_freq_total["perc"] = language_freq_total["count"] / language_freq_total["total"] * 100

with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.expand_frame_repr', False):
    with open(output_filepath, "w") as output_file:
        print(f"RQ4 Context:", file=output_file)
        print(f"* Pairs: {num_pairs}", file=output_file)
        print(f"* CVEs: {num_cves}", file=output_file)
        print(f"* CWEs: {num_cwes}", file=output_file)
        print(f"* Repos: {num_repos}", file=output_file)
        print(f"* Fix Categories: {num_categories}", file=output_file)
        print(file=output_file)
        print(f"* Fix Categories (Overall):", file=output_file)
        print(categories_occurances, file=output_file)
        print(file=output_file)
        print("* Fix Categories (Top-25 CWE)", file=output_file)
        print(categories_freq_total, file=output_file)
        print(file=output_file)
        print("* Fix Categories (Languages)", file=output_file)
        print(language_freq_total, file=output_file)
