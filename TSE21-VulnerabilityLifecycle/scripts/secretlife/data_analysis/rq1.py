import os
import sys

import pandas as pd

sys.path.insert(0, "../common")
from utils import show_boxplots


if len(sys.argv) < 2:
    print("Need to specify the directory containing the input data. Exiting.")
    sys.exit(1)
input_dir = sys.argv[1] # e.g., ../../../data/
if len(sys.argv) < 3:
    print("Need to specify the directory containing the output data. Exiting.")
    sys.exit(1)
output_dir = sys.argv[2] # e.g., ../../../results/

input_filepath = os.path.join(input_dir, "rq1_input.csv")
top_25_filepath = os.path.join(input_dir, "top25cwe.csv")
output_filepath = os.path.join(output_dir, "rq1/output.txt")

vccs_per_cve_overall_summary_filepath = os.path.join(output_dir, "rq1/overall/vccs_per_cve.csv")
vccs_per_cve_cwe_summary_filepath = os.path.join(output_dir, "rq1/cwes/vccs_per_cve.csv")
vccs_per_cve_cwe_boxplots_filepath = os.path.join(output_dir, "rq1/cwes/boxplots/vccs_per_cve_cwe_{}.pdf")

files_per_vcc_overall_summary_filepath = os.path.join(output_dir, "rq1/overall/files_per_vcc.csv")
files_per_vcc_cwe_summary_filepath = os.path.join(output_dir, "rq1/cwes/files_per_vcc.csv")
files_per_vcc_cwe_boxplots_filepath = os.path.join(output_dir, "rq1/cwes/boxplots/files_per_vcc_cwe_{}.pdf")
files_previous_changes_first_vcc_summary_filepath = os.path.join(output_dir, "rq1/overall/files_previous_changes_first_vcc.csv")
files_previous_changes_last_vcc_summary_filepath = os.path.join(output_dir, "rq1/overall/files_previous_changes_last_vcc.csv")

df_vccs = pd.read_csv(input_filepath, delimiter=",")
top_25 = pd.read_csv(top_25_filepath)[["cwe", "position"]]
df_vccs_top_25 = df_vccs[df_vccs["cwe"].isin(top_25["cwe"])]
cve_groups = df_vccs.groupby("cve", sort=False)
vcc_groups = df_vccs.groupby(["repo", "hash"], sort=False)

# General Profiling
num_vccs = df_vccs.groupby(["repo", "hash"]).size().count()
num_repos = df_vccs["repo"].nunique()
num_cwes = df_vccs["cwe"].nunique()
num_files = df_vccs.groupby(["repo", "file"]).size().count()

# Part 1: VCCs per CVE

## (Overall) Summary
num_cves = len(cve_groups)
vccs_per_cve = cve_groups["hash"].nunique()
vccs_per_cve.describe().to_csv(vccs_per_cve_overall_summary_filepath)

## (Overall) CVEs with > 1 VCCs
cve_with_many_vccs_count = (vccs_per_cve > 1).sum()
cve_with_many_vccs_perc = cve_with_many_vccs_count / num_cves * 100

## (Overall) CVEs w/ largest number of VCCs
vccs_per_cve_idxmax = vccs_per_cve.idxmax()
vccs_per_cve_max = vccs_per_cve.max()
cve_max_vccs = cve_groups.get_group(vccs_per_cve_idxmax)
cve_max_vccs_files_count = cve_max_vccs["file"].nunique()
cve_max_vccs_added_lines = cve_max_vccs["added_lines"].sum()
cve_max_vccs_removed_lines = cve_max_vccs["removed_lines"].sum()

## (Per CWEs) Summary and Boxplots

### Makes the "double" groupby and then orders according to the Top 25 order
vccs_per_cve_cwe = df_vccs_top_25 \
    .groupby("cwe", sort=False)[["hash", "cve"]] \
    .apply(lambda x: x.groupby("cve", sort=False).nunique()) \
    .reset_index() \
    .merge(top_25, how="left", on="cwe") \
    .sort_values("position", ignore_index=True) \
    .drop(columns=["cve", "position"])
vccs_per_cve_cwe.groupby("cwe", sort=False)["hash"].describe().to_csv(vccs_per_cve_cwe_summary_filepath)
show_boxplots(vccs_per_cve_cwe, "cwe", "hash", "VCCs per CVE", vccs_per_cve_cwe_boxplots_filepath, log=True)

# Part 2: Touched Files per VCC

## (Overall) Summary
files_per_vcc = vcc_groups["file"].nunique()
files_per_vcc.describe().to_csv(files_per_vcc_overall_summary_filepath)

## (Overall) VCCs touching > 10 files
vccs_more_ten_files_count = files_per_vcc[files_per_vcc > 10].count()
vccs_more_ten_files_perc = vccs_more_ten_files_count / num_vccs * 100

## (Overall) VCC w/ largest number of Files
files_per_vcc_idxmax = files_per_vcc.idxmax()
files_per_vcc_idxmax_repo = files_per_vcc_idxmax[0]
files_per_vcc_idxmax_hash = files_per_vcc_idxmax[1]
files_per_vcc_max = files_per_vcc.max()
vcc_max_files = vcc_groups.get_group(files_per_vcc_idxmax)
vcc_max_files_count = vcc_max_files["file"].nunique()
vcc_max_cve_counts = vcc_max_files["cve"].value_counts()
vcc_max_files_added_lines = vcc_max_files["added_lines"].iloc[0]
vcc_max_files_removed_lines = vcc_max_files["removed_lines"].iloc[0]

## (Per CWEs) Summary and Boxplots
files_per_vcc_cwe = df_vccs_top_25 \
    .groupby("cwe", sort=False)[["repo", "hash", "file"]] \
    .apply(lambda x: x.groupby(["repo", "hash"], sort=False).nunique()) \
    .reset_index() \
    .merge(top_25, how="left", on="cwe") \
    .sort_values("position", ignore_index=True) \
    .drop(columns=["repo", "hash", "position"])
files_per_vcc_cwe.groupby("cwe", sort=False)["file"].describe().to_csv(files_per_vcc_cwe_summary_filepath)
show_boxplots(files_per_vcc_cwe, "cwe", "file", "Touched Files per VCC", files_per_vcc_cwe_boxplots_filepath, log=True)

# Part 3: Number of Previous Changes for files in First/Last VCC

## (Overall) Summary

df_vccs_first = df_vccs[cve_groups["date"].transform(min) == df_vccs["date"]]
previous_changes_vccs_first = df_vccs_first["previous_changes"]
df_vccs_last = df_vccs[cve_groups["date"].transform(max) == df_vccs["date"]]
previous_changes_vccs_last = df_vccs_last["previous_changes"]
previous_changes_vccs_first.describe().to_csv(files_previous_changes_first_vcc_summary_filepath)
previous_changes_vccs_last.describe().to_csv(files_previous_changes_last_vcc_summary_filepath)

# Part 4: Files that were created in a VCC (i.e., previous_changes == 0) + Files that were created in a VCC that is the sole the CVE
files_created_vcc = df_vccs.loc[df_vccs["previous_changes"] == 0, ["repo", "file"]].drop_duplicates(ignore_index=True)
files_cves_one_vcc = cve_groups.filter(lambda x: len(x) == 1)[["repo", "file"]].drop_duplicates(ignore_index=True)
files_cves_one_vcc_created = pd.merge(files_created_vcc, files_cves_one_vcc, on=["repo", "file"])
files_created_vcc_count = len(files_created_vcc)
files_cves_one_vcc_created_count = len(files_cves_one_vcc_created)

# Part 5: Files that were changed > 500 times before VCC
files_first_vcc = df_vccs[df_vccs.groupby(["repo", "file"], sort=False)["previous_changes"].transform(min) == df_vccs["previous_changes"]]
files_over_500 = files_first_vcc.loc[files_first_vcc["previous_changes"] > 500, ["repo", "file", "previous_changes"]].sort_values(by="previous_changes", ascending=False, ignore_index=True)
files_over_500_count = len(files_over_500)

with open(output_filepath, "w") as output_file:
    print(f"RQ1 Context:", file=output_file)
    print(f"* CVEs: {num_cves}", file=output_file)
    print(f"* VCCs: {num_vccs}", file=output_file)
    print(f"* Repos: {num_repos}", file=output_file)
    print(f"* CWEs: {num_cwes}", file=output_file)
    print(f"* Files (distinct): {num_files}", file=output_file)
    print(file=output_file)
    print(f"RQ1 Main Results:", file=output_file)
    print(f"* CVEs with > 1 VCC: {cve_with_many_vccs_count}/{num_cves} ({round(cve_with_many_vccs_perc, 2)}%)", file=output_file)
    print(f"* {vccs_per_cve_idxmax} has the largest number of VCCs: {vccs_per_cve_max}. Considering all VCCs:", file=output_file)
    print(f"  - Touched a total of {cve_max_vccs_files_count} valid files", file=output_file)
    print(f"  - Added a total of {cve_max_vccs_added_lines} lines", file=output_file)
    print(f"  - Removed a total of {cve_max_vccs_removed_lines} lines", file=output_file)
    print(file=output_file)
    print(f"* VCCs that touched > 10 files: {vccs_more_ten_files_count}/{num_vccs} ({round(vccs_more_ten_files_perc, 2)}%)", file=output_file)
    print(f"* VCC {files_per_vcc_idxmax_hash} of {files_per_vcc_idxmax_repo} touched the largest number of valid files: {files_per_vcc_max}. Specifically:", file=output_file)
    print(f"  - Contributed to: {vcc_max_cve_counts.index.values}", file=output_file) 
    print(f"  - Touched {vcc_max_files_count} valid files", file=output_file)
    print(f"  - Added {vcc_max_files_added_lines} lines", file=output_file)
    print(f"  - Removed {vcc_max_files_removed_lines} lines", file=output_file)
    print(f"* Files created within a VCC: {files_created_vcc_count}/{num_files} ({round(files_created_vcc_count / num_files * 100, 2)}%)", file=output_file)
    print(f"  - Files created in \"single-VCC\" vulnerabilities: {files_cves_one_vcc_created_count}/{files_created_vcc_count} ({round(files_cves_one_vcc_created_count / files_created_vcc_count * 100, 2)}%)", file=output_file)
    print(f"* Files that started becoming vulnerable after >= 500 commits: {files_over_500_count}/{num_files} ({round(files_over_500_count / num_files * 100, 2)}%)", file=output_file)
