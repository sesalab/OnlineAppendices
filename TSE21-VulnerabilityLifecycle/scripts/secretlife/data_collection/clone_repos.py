import json
import os
import shutil
import signal
import sys

from git import GitCommandError, Repo
from pydriller import Git

sys.path.insert(0, "../common/")
from utils import (export_update, get_full_project_name, get_processed_repos,
                   get_repos, is_git_repo)

in_filepath = "../../../data/cves.json"

def terminate():
    num_cloned_repos = len(os.listdir(dest))
    print("Terminated with a total of {} repositories.".format(num_cloned_repos))
    sys.exit(0)


def sigint_handler(sig, frame):
    print("\nCTRL+C issued: aborting.")
    terminate()


def clone_repo(repo_url):
    parts = repo_url.split('://', 1)
    # This automatically skips private repositories
    repo_url_no_credentials = parts[0] + "://:@" + parts[1]
    try:
        print("Cloning from remote...")
        Repo.clone_from(repo_url_no_credentials, repo_dest_path)
        print("Cloning done!")
    except GitCommandError as ger:
        raise ger
    git_repo = Git(repo_dest_path)
    git_repo.reset()
    return git_repo

if len(sys.argv) < 2:
    print("Need to specify the destination directory path as argument. Exiting.")
    sys.exit(1)
# Ensure the supplied path is valid
dest = sys.argv[1]
if not os.path.isdir(dest):
    os.makedirs(dest)
if len(sys.argv) < 3:
    print("Need to specify the file containing the enriched repositories. Exiting.")
    sys.exit(1)
enriched_repos_filepath = sys.argv[2] # ../../../data/repos_enriched.json
if len(sys.argv) < 4:
    print("Need to specify the file containing the discarded repositories. Exiting.")
    sys.exit(1)
discarded_repos_filepath = sys.argv[3] # ../../../data/repos_discarded.json

# Register SIGINT handler
signal.signal(signal.SIGINT, sigint_handler)

# Import repository names from the input json
cves = []
with open(in_filepath, "r") as in_file:
    cves = json.load(in_file)
all_repos = get_repos(cves)
# Exclude repositories already processed
processed_repos = get_processed_repos(enriched_repos_filepath, discarded_repos_filepath)
print(f"Repositories already processed (enriched or discarded) to be ignored: {processed_repos}")
repos = [repo for repo in all_repos if repo not in processed_repos]
num_repos = len(repos)
print("Repositories: {}".format(num_repos))

# Loop and clone each repository
current_repo = 0
for repo_url in repos:
    current_repo += 1
    print("\n({}/{}) About to clone {}".format(current_repo, num_repos, repo_url))
    full_project_name = get_full_project_name(repo_url)
    repo_dest_path = os.path.join(dest, full_project_name)
    if os.path.exists(repo_dest_path):
        if is_git_repo(repo_dest_path):
            print("Repository already clone. Skipping.")
            continue
        else:
            shutil.rmtree(repo_dest_path)
    try:
        _ = clone_repo(repo_url)
    except GitCommandError:
        print("Clone failed, skipping repository...")
        export_update({"repo": repo_url, "reason": "UNAVAILABLE"}, discarded_repos_filepath)
        continue

terminate()
