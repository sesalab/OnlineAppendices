import json
import re
import sys

from tqdm import tqdm

sys.path.insert(0, "../common")
from utils import call_api

in_file_path = "../../../data/nvd_raw.json"
out_file_path = "../../../data/cves.json"
endpoint = "https://cve.circl.lu/api/cve/"

# Import from Json
data = []
with open(in_file_path, "r") as in_file:
    data = json.load(in_file)

cves = data["cves"]
cve_list = []
total_cves = len(cves)
no_data = 0
no_fixes = 0
multi_repos = 0

for cve, val in tqdm(cves.items()):
    if "refmap" not in val:
        no_data += 1
        continue
    refmap = val["refmap"]
    confirm = []
    if "confirm" in refmap:
        confirm = refmap["confirm"]
    misc = []
    if "misc" in refmap:
        misc = refmap["misc"]
    github_fix_regex = r"http(s)?:\/\/(www.)?github.com\/.*\/commit\/.*"
    confirm_fixes = list(filter(re.compile(github_fix_regex).match, confirm))
    misc_fixes = list(filter(re.compile(github_fix_regex).match, misc))
    repo_fixes = confirm_fixes + misc_fixes
    # Filter out CVEs without GitHub fixing commits
    if len(repo_fixes) == 0:
        no_fixes += 1
        continue
    response = call_api(endpoint + cve)
    fixes = []
    for repo_fix in repo_fixes:
        repo_fix_split = repo_fix.split("/commit/", 2)
        repo = repo_fix_split[0]
        # Removes the possible #diff suffix and query parameters 
        fix_hash = repo_fix_split[1].split('#', 1)[0].split('?', 1)[0]                

        # Handle special cases of strange commit IDs
        if fix_hash == "curl-7_51_0-162-g3ab3c16":
            fix_hash = "3ab3c16db6a5674f53cf23d56512a405fde0b2c9"
        if fix_hash == "curl-7_50_2~32":
            fix_hash = "7700fcba64bf5806de28f6c1c7da3b4f0b38567d"
        
        fixes.append({
            "repo": repo,
            "hash": fix_hash
        })
    # Exclude CVEs with fixes in different repos
    repos = [fix["repo"] for fix in fixes]
    num_repos = len(set(repos))
    if num_repos == 1:
        cve_list.append({
            "cve": cve,
            "cwe": response["cwe"],
            "cvss": response["cvss"],
            "cvss-vector": response["cvss-vector"],
            #"cpes": response["vulnerable_product"],
            "fixes": fixes
        })
    elif num_repos > 1:
        multi_repos +=1

# Export to Json
with open(out_file_path, "w") as out_file:
    json.dump(cve_list, out_file, indent=2)

# Some general measures

## Number of selected CVEs
selected_cves = len(cve_list)

## Number of selected CVEs w/ multiple fixes
cve_multiple_fixes = 0
for cve in cve_list:
    if len(cve["fixes"]) > 1:
        cve_multiple_fixes += 1

with open("../../../results/data_collection/output.txt", "w") as outfile:
    print("Number of Discarded CVEs because of No Data: {}/{}".format(no_data, total_cves), file=outfile)
    print("Number of Discarded CVEs because of No Fixes: {}/{}".format(no_fixes, total_cves), file=outfile)
    print("Number of Discarded CVEs because of Multiple Repos: {}/{}".format(multi_repos, total_cves), file=outfile)
    print("Number of Selected CVEs: {}/{}".format(selected_cves, total_cves), file=outfile)
    print("- Number of CVEs w/ multiple fixes: {}/{}".format(cve_multiple_fixes, selected_cves), file=outfile)
